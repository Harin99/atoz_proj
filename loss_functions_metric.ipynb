{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "9TE_uWY_BNdG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Segmentation Cross Entropy"
      ],
      "metadata": {
        "id": "z7KcCVJvBCAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_2d(\n",
        "    logits: torch.Tensor,\n",
        "    target: torch.Tensor,\n",
        "    ignore_index: int | None = None,\n",
        "    reduction: str = \"mean\",\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    2D segmentation에 사용하는 Cross Entropy loss를 직접 구현.\n",
        "\n",
        "    Args:\n",
        "        logits: (B, C, H, W)\n",
        "            - 각 픽셀에 대한 class별 logit 값\n",
        "        target: (B, H, W), dtype=torch.long\n",
        "            - 각 픽셀의 class index (0 ~ C-1)\n",
        "        ignore_index: int or None\n",
        "            - 이 값의 label은 loss 계산에서 제외 (ex. -1)\n",
        "        reduction: \"none\" | \"mean\" | \"sum\"\n",
        "\n",
        "    Returns:\n",
        "        loss: scalar tensor or (B, H, W) (reduction=\"none\"일 때)\n",
        "    \"\"\"\n",
        "    B, C, H, W = logits.shape\n",
        "    # (B, C, H, W) -> (B, H, W, C) -> (B*H*W, C)\n",
        "    logits_flat = logits.permute(0, 2, 3, 1).reshape(-1, C)\n",
        "    target_flat = target.view(-1)  # (B*H*W,)\n",
        "\n",
        "    if ignore_index is not None:\n",
        "        # 사용할 위치 mask\n",
        "        valid_mask = target_flat != ignore_index\n",
        "        logits_flat = logits_flat[valid_mask]            # (N_valid, C)\n",
        "        target_flat = target_flat[valid_mask]            # (N_valid,)\n",
        "\n",
        "    # numerical stable을 위해 log_softmax 사용\n",
        "    log_probs = F.log_softmax(logits_flat, dim=1)        # (N_valid, C)\n",
        "    # 각 sample의 정답 class의 log prob만 gather\n",
        "    # target_flat: (N_valid,), unsqueeze -> (N_valid, 1)\n",
        "    loss = -log_probs.gather(dim=1, index=target_flat.unsqueeze(1)).squeeze(1)  # (N_valid,)\n",
        "\n",
        "    if reduction == \"none\":\n",
        "        # 원래 (B, H, W) shape으로 되돌릴 수도 있지만,\n",
        "        # 여기서는 일단 1D로만 반환\n",
        "        return loss\n",
        "    elif reduction == \"mean\":\n",
        "        return loss.mean()\n",
        "    elif reduction == \"sum\":\n",
        "        return loss.sum()\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid reduction: {reduction}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "xL3ZvWElBJDH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_ce = cross_entropy_2d(logits, target, ignore_index=-1)\n",
        "# logits: (B,C,H,W), target: (B,H,W)"
      ],
      "metadata": {
        "id": "xRXAPnQ_BRgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Dice Loss (binary & multi-class)"
      ],
      "metadata": {
        "id": "4LCzI4i9BSDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_dice_loss(\n",
        "    logits: torch.Tensor,\n",
        "    target: torch.Tensor,\n",
        "    eps: float = 1e-6,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Binary segmentation용 Dice loss.\n",
        "    내부에서 sigmoid를 적용한다고 가정.\n",
        "\n",
        "    Args:\n",
        "        logits: (B, 1, H, W) or (B, H, W)\n",
        "            - 각 픽셀의 foreground logit 값\n",
        "        target: (B, 1, H, W) or (B, H, W)\n",
        "            - 각 픽셀의 GT (0 또는 1)\n",
        "        eps:\n",
        "            - 분모가 0되는 상황 방지용 small constant\n",
        "\n",
        "    Returns:\n",
        "        dice_loss: scalar tensor\n",
        "    \"\"\"\n",
        "    # shape 정리: 항상 (B, 1, H, W)로 맞추기\n",
        "    if logits.dim() == 3:\n",
        "        logits = logits.unsqueeze(1)   # (B, 1, H, W)\n",
        "    if target.dim() == 3:\n",
        "        target = target.unsqueeze(1)   # (B, 1, H, W)\n",
        "\n",
        "    probs = torch.sigmoid(logits)      # (B, 1, H, W)\n",
        "    target = target.float()\n",
        "\n",
        "    # (B, 1, H, W) -> (B, -1)\n",
        "    probs_flat = probs.view(probs.size(0), -1)\n",
        "    target_flat = target.view(target.size(0), -1)\n",
        "\n",
        "    intersection = (probs_flat * target_flat).sum(dim=1)   # (B,)\n",
        "    union = probs_flat.sum(dim=1) + target_flat.sum(dim=1) # (B,)\n",
        "\n",
        "    dice = (2 * intersection + eps) / (union + eps)        # (B,)\n",
        "    dice_loss = 1 - dice.mean()\n",
        "    return dice_loss\n",
        "\n",
        "\n",
        "def multiclass_dice_loss(\n",
        "    logits: torch.Tensor,\n",
        "    target: torch.Tensor,\n",
        "    ignore_index: int | None = None,\n",
        "    eps: float = 1e-6,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Multi-class segmentation용 Dice loss.\n",
        "    내부에서 softmax로 확률을 만들고, target은 one-hot으로 변환.\n",
        "\n",
        "    Args:\n",
        "        logits: (B, C, H, W)\n",
        "            - 각 픽셀의 class별 logit\n",
        "        target: (B, H, W), dtype=torch.long\n",
        "            - 각 픽셀의 class index\n",
        "        ignore_index: int or None\n",
        "            - 이 class index는 dice에서 제외\n",
        "        eps:\n",
        "            - 분모가 0되는 상황 방지용 small constant\n",
        "\n",
        "    Returns:\n",
        "        dice_loss: scalar tensor (모든 class 평균 Dice loss)\n",
        "    \"\"\"\n",
        "    B, C, H, W = logits.shape\n",
        "\n",
        "    # (B, C, H, W) -> softmax -> (B, C, H, W)\n",
        "    probs = F.softmax(logits, dim=1)\n",
        "\n",
        "    # target: (B, H, W) -> one-hot: (B, H, W, C) -> (B, C, H, W)\n",
        "    target_onehot = F.one_hot(\n",
        "        target.clamp(min=0), num_classes=C\n",
        "    ).permute(0, 3, 1, 2).float()  # 음수(ignore_index 방지용 clamp)\n",
        "\n",
        "    # ignore_index가 있는 경우, 해당 위치를 모두 0으로 mask 처리\n",
        "    if ignore_index is not None:\n",
        "        ignore_mask = (target == ignore_index).unsqueeze(1)  # (B,1,H,W)\n",
        "        target_onehot[ignore_mask.expand_as(target_onehot)] = 0.0\n",
        "        probs = probs.masked_fill(ignore_mask.expand_as(probs), 0.0)\n",
        "\n",
        "    # (B, C, H, W) -> (B, C, -1)\n",
        "    probs_flat = probs.view(B, C, -1)\n",
        "    target_flat = target_onehot.view(B, C, -1)\n",
        "\n",
        "    intersection = (probs_flat * target_flat).sum(dim=2)        # (B, C)\n",
        "    union = probs_flat.sum(dim=2) + target_flat.sum(dim=2)      # (B, C)\n",
        "\n",
        "    dice = (2 * intersection + eps) / (union + eps)             # (B, C)\n",
        "    # batch, class 평균\n",
        "    dice_loss = 1 - dice.mean()\n",
        "    return dice_loss"
      ],
      "metadata": {
        "id": "u6UbSO4zBSFg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Binary dice\n",
        "loss_dice_bin = binary_dice_loss(bin_logits, bin_target)\n",
        "# bin_logits: (B,1,H,W), bin_target: (B,1,H,W)\n",
        "\n",
        "## Multi-class Dice\n",
        "loss_dice_mc = multiclass_dice_loss(logits, target, ignore_index=-1)\n",
        "# logits: (B,C,H,W), target: (B,H,W)\n"
      ],
      "metadata": {
        "id": "EKK5c6KdBSH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Segmentation IoU / mIoU metric"
      ],
      "metadata": {
        "id": "jnyGjnXJBSKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_binary_iou(\n",
        "    logits: torch.Tensor,\n",
        "    target: torch.Tensor,\n",
        "    threshold: float = 0.5,\n",
        "    eps: float = 1e-6,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Binary segmentation에서 IoU 계산.\n",
        "\n",
        "    Args:\n",
        "        logits: (B, 1, H, W) or (B, H, W)\n",
        "            - foreground logit\n",
        "        target: (B, 1, H, W) or (B, H, W)\n",
        "            - GT (0 또는 1)\n",
        "        threshold:\n",
        "            - sigmoid(logits) >= threshold 를 positive로 판정\n",
        "        eps:\n",
        "            - 0으로 나누기 방지\n",
        "\n",
        "    Returns:\n",
        "        mean_iou: scalar tensor (batch 평균 IoU)\n",
        "    \"\"\"\n",
        "    if logits.dim() == 3:\n",
        "        logits = logits.unsqueeze(1)  # (B,1,H,W)\n",
        "    if target.dim() == 3:\n",
        "        target = target.unsqueeze(1)  # (B,1,H,W)\n",
        "\n",
        "    probs = torch.sigmoid(logits)\n",
        "    pred = (probs >= threshold).float()  # (B,1,H,W)\n",
        "    target = target.float()\n",
        "\n",
        "    # (B,1,H,W) -> (B,-1)\n",
        "    pred_flat = pred.view(pred.size(0), -1)\n",
        "    target_flat = target.view(target.size(0), -1)\n",
        "\n",
        "    intersection = (pred_flat * target_flat).sum(dim=1)        # (B,)\n",
        "    union = pred_flat.sum(dim=1) + target_flat.sum(dim=1) - intersection  # (B,)\n",
        "    iou = (intersection + eps) / (union + eps)                 # (B,)\n",
        "    return iou.mean()\n",
        "\n",
        "\n",
        "def compute_multiclass_iou(\n",
        "    logits: torch.Tensor,\n",
        "    target: torch.Tensor,\n",
        "    num_classes: int,\n",
        "    ignore_index: int | None = None,\n",
        "    eps: float = 1e-6,\n",
        ") -> tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Multi-class segmentation IoU / mIoU 계산.\n",
        "\n",
        "    Args:\n",
        "        logits: (B, C, H, W)\n",
        "            - class별 logit\n",
        "        target: (B, H, W), dtype=torch.long\n",
        "            - GT class index\n",
        "        num_classes: int\n",
        "            - class 개수 C\n",
        "        ignore_index: int or None\n",
        "            - 이 label은 metric 계산에서 제외\n",
        "        eps:\n",
        "            - 0으로 나누기 방지\n",
        "\n",
        "    Returns:\n",
        "        iou_per_class: (C,) tensor\n",
        "        miou: scalar tensor (유효 class만 평균)\n",
        "    \"\"\"\n",
        "    # pred: (B, H, W), 예측 class index\n",
        "    pred = logits.argmax(dim=1)  # (B, H, W)\n",
        "\n",
        "    # ignore_index가 있으면 해당 위치는 빼버린다.\n",
        "    if ignore_index is not None:\n",
        "        mask = target != ignore_index  # (B,H,W)\n",
        "        pred = pred[mask]\n",
        "        target = target[mask]\n",
        "    else:\n",
        "        mask = torch.ones_like(target, dtype=torch.bool)\n",
        "        pred = pred[mask]\n",
        "        target = target[mask]\n",
        "\n",
        "    # 이제 pred, target: (N,) 이고 각 값은 [0, num_classes-1]\n",
        "    iou_per_class = pred.new_zeros(num_classes, dtype=torch.float32)\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        pred_c = pred == c  # (N,)\n",
        "        target_c = target == c  # (N,)\n",
        "\n",
        "        intersection = (pred_c & target_c).sum().float()\n",
        "        union = (pred_c | target_c).sum().float()\n",
        "\n",
        "        if union == 0:\n",
        "            # 아예 등장하지 않은 class -> NaN 대신 0으로 두고, 나중에 평균에서 제외해도 됨.\n",
        "            iou = torch.tensor(0.0, device=logits.device)\n",
        "        else:\n",
        "            iou = (intersection + eps) / (union + eps)\n",
        "\n",
        "        iou_per_class[c] = iou\n",
        "\n",
        "    # union이 0인 class는 제외하고 평균내고 싶다면:\n",
        "    valid_classes = iou_per_class > 0  # union==0이면 0이므로 자동 제외\n",
        "    if valid_classes.any():\n",
        "        miou = iou_per_class[valid_classes].mean()\n",
        "    else:\n",
        "        miou = torch.tensor(0.0, device=logits.device)\n",
        "\n",
        "    return iou_per_class, miou"
      ],
      "metadata": {
        "id": "WFwZ3nvgBSNO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 1. Binary IoU\n",
        "iou_bin = compute_binary_iou(bin_logits, bin_target)\n",
        "\n",
        "## 2. Multi-class iou / miou\n",
        "iou_per_class, miou = compute_multiclass_iou(logits, target, num_classes=C, ignore_index=-1)"
      ],
      "metadata": {
        "id": "xCG0clxLBSP6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Focal loss"
      ],
      "metadata": {
        "id": "VwqZIogXBSSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def focal_loss(\n",
        "    logits: torch.Tensor,\n",
        "    target: torch.Tensor,\n",
        "    gamma: float = 2.0,\n",
        "    alpha: float | None = None,\n",
        "    reduction: str = \"mean\",\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Multi-class classification/segmentation용 Focal Loss (CrossEntropy 기반).\n",
        "\n",
        "    Args:\n",
        "        logits: (B, C, ...)  (예: (B,C,H,W)도 가능)\n",
        "            - class별 logit\n",
        "        target: (B, ...) dtype=torch.long\n",
        "            - 정답 class index (0 ~ C-1)\n",
        "        gamma:\n",
        "            - focusing parameter (보통 2.0)\n",
        "        alpha:\n",
        "            - class imbalance weighting (scalar)\n",
        "              (보통 0.25 등, 여기서는 모든 class에 동일하게 적용)\n",
        "        reduction: \"none\" | \"mean\" | \"sum\"\n",
        "\n",
        "    Returns:\n",
        "        focal_loss: scalar tensor 또는 sample별 loss\n",
        "    \"\"\"\n",
        "    # logits: (B, C, ...) -> (N, C)\n",
        "    num_classes = logits.size(1)\n",
        "    logits_flat = logits.permute(0, *range(2, logits.dim()), 1).reshape(-1, num_classes)\n",
        "    target_flat = target.view(-1)\n",
        "\n",
        "    # log_softmax & softmax\n",
        "    log_probs = F.log_softmax(logits_flat, dim=1)        # (N, C)\n",
        "    probs = log_probs.exp()                              # (N, C)\n",
        "\n",
        "    # 정답 class의 p_t, log_p_t\n",
        "    # target_flat: (N,) -> (N,1)\n",
        "    target_flat_clamped = target_flat.clamp(min=0)       # 음수 방지용\n",
        "    log_p_t = log_probs.gather(dim=1, index=target_flat_clamped.unsqueeze(1)).squeeze(1)  # (N,)\n",
        "    p_t = probs.gather(dim=1, index=target_flat_clamped.unsqueeze(1)).squeeze(1)          # (N,)\n",
        "\n",
        "    # focal term\n",
        "    focal_term = (1 - p_t) ** gamma                      # (N,)\n",
        "\n",
        "    loss = -focal_term * log_p_t                         # (N,)\n",
        "\n",
        "    # alpha가 주어지면 weight 곱해줌\n",
        "    if alpha is not None:\n",
        "        loss = alpha * loss\n",
        "\n",
        "    if reduction == \"none\":\n",
        "        return loss.view_as(target)\n",
        "    elif reduction == \"mean\":\n",
        "        return loss.mean()\n",
        "    elif reduction == \"sum\":\n",
        "        return loss.sum()\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid reduction: {reduction}\")"
      ],
      "metadata": {
        "id": "Sr8kRZzhBSU_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_focal = focal_loss(logits, target, gamma=2.0, alpha=0.25)"
      ],
      "metadata": {
        "id": "s0ffmGijBSXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Bounding box IoU / GIoU"
      ],
      "metadata": {
        "id": "lBgIH2kiBlDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def box_area(boxes: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Axis-aligned box area 계산.\n",
        "\n",
        "    Args:\n",
        "        boxes: (N, 4) = (x1, y1, x2, y2)\n",
        "\n",
        "    Returns:\n",
        "        area: (N,)\n",
        "    \"\"\"\n",
        "    # clamp로 음수 방지 (x2 < x1인 경우 등)\n",
        "    return ((boxes[:, 2] - boxes[:, 0]).clamp(min=0) *\n",
        "            (boxes[:, 3] - boxes[:, 1]).clamp(min=0))\n",
        "\n",
        "\n",
        "def box_iou(boxes1: torch.Tensor, boxes2: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    두 집합의 axis-aligned bounding boxes 사이의 IoU matrix 계산.\n",
        "\n",
        "    Args:\n",
        "        boxes1: (N, 4) = (x1, y1, x2, y2)\n",
        "        boxes2: (M, 4) = (x1, y1, x2, y2)\n",
        "\n",
        "    Returns:\n",
        "        iou: (N, M)\n",
        "            - iou[i, j] = IoU(boxes1[i], boxes2[j])\n",
        "    \"\"\"\n",
        "    area1 = box_area(boxes1)  # (N,)\n",
        "    area2 = box_area(boxes2)  # (M,)\n",
        "\n",
        "    # 각 pair의 교집합 좌상단/우하단 좌표 계산\n",
        "    # (N,1) vs (M,) -> broadcasting으로 (N,M) 만들기\n",
        "    x1 = torch.max(boxes1[:, 0].unsqueeze(1), boxes2[:, 0].unsqueeze(0))  # (N,M)\n",
        "    y1 = torch.max(boxes1[:, 1].unsqueeze(1), boxes2[:, 1].unsqueeze(0))  # (N,M)\n",
        "    x2 = torch.min(boxes1[:, 2].unsqueeze(1), boxes2[:, 2].unsqueeze(0))  # (N,M)\n",
        "    y2 = torch.min(boxes1[:, 3].unsqueeze(1), boxes2[:, 3].unsqueeze(0))  # (N,M)\n",
        "\n",
        "    inter_w = (x2 - x1).clamp(min=0)  # (N,M)\n",
        "    inter_h = (y2 - y1).clamp(min=0)  # (N,M)\n",
        "    inter = inter_w * inter_h         # (N,M)\n",
        "\n",
        "    union = area1.unsqueeze(1) + area2.unsqueeze(0) - inter  # (N,M)\n",
        "    iou = inter / union.clamp(min=1e-6)                      # (N,M)\n",
        "    return iou\n",
        "\n",
        "\n",
        "def generalized_box_iou(boxes1: torch.Tensor, boxes2: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    두 집합 bounding box의 Generalized IoU 계산.\n",
        "\n",
        "    GIoU = IoU - (|C \\ U| / |C|)\n",
        "    C: 두 box를 둘 다 포함하는 최소 bounding box.\n",
        "\n",
        "    Args:\n",
        "        boxes1: (N, 4)\n",
        "        boxes2: (M, 4)\n",
        "\n",
        "    Returns:\n",
        "        giou: (N, M)\n",
        "    \"\"\"\n",
        "    # 기본 IoU\n",
        "    iou = box_iou(boxes1, boxes2)  # (N,M)\n",
        "\n",
        "    # 각 pair의 enclosing box C 계산\n",
        "    x1_c = torch.min(boxes1[:, 0].unsqueeze(1), boxes2[:, 0].unsqueeze(0))  # (N,M)\n",
        "    y1_c = torch.min(boxes1[:, 1].unsqueeze(1), boxes2[:, 1].unsqueeze(0))  # (N,M)\n",
        "    x2_c = torch.max(boxes1[:, 2].unsqueeze(1), boxes2[:, 2].unsqueeze(0))  # (N,M)\n",
        "    y2_c = torch.max(boxes1[:, 3].unsqueeze(1), boxes2[:, 3].unsqueeze(0))  # (N,M)\n",
        "\n",
        "    c_w = (x2_c - x1_c).clamp(min=0)\n",
        "    c_h = (y2_c - y1_c).clamp(min=0)\n",
        "    area_c = c_w * c_h  # (N,M)\n",
        "\n",
        "    # 각각의 area와 IoU는 이미 계산됨.\n",
        "    area1 = box_area(boxes1).unsqueeze(1)  # (N,1)\n",
        "    area2 = box_area(boxes2).unsqueeze(0)  # (1,M)\n",
        "    inter = iou * (area1 + area2 - iou * (area1 + area2))  # 다시 구해도 되지만 여기선 트릭 X, 그냥 다시 계산하는게 안전함.\n",
        "\n",
        "    # inter를 다시 정확히 계산하기 위해 box_iou 내부 로직 재사용하는 게 더 깔끔이긴 한데,\n",
        "    # 여기서는 IoU와 union에서 역산하는 대신, 다시 intersection을 계산하는 방식을 추천.\n",
        "    # → 간단하게 다시 계산하자 (코드 중복을 살짝 감수).\n",
        "    x1 = torch.max(boxes1[:, 0].unsqueeze(1), boxes2[:, 0].unsqueeze(0))\n",
        "    y1 = torch.max(boxes1[:, 1].unsqueeze(1), boxes2[:, 1].unsqueeze(0))\n",
        "    x2 = torch.min(boxes1[:, 2].unsqueeze(1), boxes2[:, 2].unsqueeze(0))\n",
        "    y2 = torch.min(boxes1[:, 3].unsqueeze(1), boxes2[:, 3].unsqueeze(0))\n",
        "    inter_w = (x2 - x1).clamp(min=0)\n",
        "    inter_h = (y2 - y1).clamp(min=0)\n",
        "    inter = inter_w * inter_h  # (N,M)\n",
        "\n",
        "    union = area1 + area2 - inter  # (N,M)\n",
        "\n",
        "    # GIoU 공식: IoU - (|C|-|U|)/|C|\n",
        "    giou = iou - (area_c - union) / area_c.clamp(min=1e-6)\n",
        "    return giou"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjy57klEBlGV",
        "outputId": "4b03e67d-9417-4fbf-8eec-fe4ed0f4ff80"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:51: SyntaxWarning: invalid escape sequence '\\ '\n",
            "<>:51: SyntaxWarning: invalid escape sequence '\\ '\n",
            "/tmp/ipython-input-174790212.py:51: SyntaxWarning: invalid escape sequence '\\ '\n",
            "  GIoU = IoU - (|C \\ U| / |C|)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iou_mat = box_iou(boxes1, boxes2)         # boxes1: (N,4), boxes2: (M,4)\n",
        "giou_mat = generalized_box_iou(boxes1, boxes2)"
      ],
      "metadata": {
        "id": "uWrLacYkBlIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cw3tEPAZBlLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Average Precision"
      ],
      "metadata": {
        "id": "m-Zcsb8xCRek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def compute_ap(recall, precision):\n",
        "    \"\"\"\n",
        "    AP = Precision-Recall 곡선의 면적\n",
        "    VOC 방식: interpolation 없이 trapezoid積분\n",
        "    \"\"\"\n",
        "    # 앞에 0, 뒤에 1 붙여 Edge 포함\n",
        "    mrec = np.concatenate(([0.0], recall, [1.0]))\n",
        "    mpre = np.concatenate(([1.0], precision, [0.0]))\n",
        "\n",
        "    # Precision envelope (단조 감소)\n",
        "    for i in range(len(mpre)-1, 0, -1):\n",
        "        mpre[i-1] = max(mpre[i-1], mpre[i])\n",
        "\n",
        "    # PR curve 면적 계산\n",
        "    idx = np.where(mrec[1:] != mrec[:-1])[0]\n",
        "    ap = np.sum((mrec[idx+1] - mrec[idx]) * mpre[idx+1])\n",
        "    return ap\n",
        "\n",
        "\n",
        "def compute_map(pred_boxes, pred_scores, gt_boxes, iou_thresh=0.5):\n",
        "    \"\"\"\n",
        "    PASCAL VOC style mAP@IoU=0.5 (single class 예제)\n",
        "\n",
        "    pred_boxes: (N_pred,4)  (x1,y1,x2,y2)\n",
        "    pred_scores: (N_pred,)  confidence score 높은 순 정렬돼있지 않아도됨\n",
        "    gt_boxes: (N_gt,4)\n",
        "    \"\"\"\n",
        "\n",
        "    # score 높은 순으로 정렬\n",
        "    indices = np.argsort(-pred_scores)\n",
        "    pred_boxes = pred_boxes[indices]\n",
        "    pred_scores = pred_scores[indices]\n",
        "\n",
        "    tp = np.zeros(len(pred_boxes))\n",
        "    fp = np.zeros(len(pred_boxes))\n",
        "    detected = np.zeros(len(gt_boxes))  # GT 매칭 여부\n",
        "\n",
        "    for i, pb in enumerate(pred_boxes):\n",
        "        # IoU 모든 GT와 계산\n",
        "        iou = box_iou(\n",
        "            torch.tensor(pb).unsqueeze(0),\n",
        "            torch.tensor(gt_boxes)\n",
        "        ).numpy().squeeze(0)  # (N_gt,)\n",
        "\n",
        "        max_iou = iou.max()\n",
        "        max_gt = iou.argmax()\n",
        "\n",
        "        if max_iou >= iou_thresh and detected[max_gt] == 0:\n",
        "            tp[i] = 1\n",
        "            detected[max_gt] = 1\n",
        "        else:\n",
        "            fp[i] = 1\n",
        "\n",
        "    # 누적 TP/FP 계산\n",
        "    tp_cum = np.cumsum(tp)\n",
        "    fp_cum = np.cumsum(fp)\n",
        "\n",
        "    recall = tp_cum / len(gt_boxes)\n",
        "    precision = tp_cum / (tp_cum + fp_cum + 1e-6)\n",
        "\n",
        "    ap = compute_ap(recall, precision)\n",
        "    return ap"
      ],
      "metadata": {
        "id": "1hpwyHPDCRhJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단일 이미지, 단일 클래스 에시\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# 예측 박스들 (x1,y1,x2,y2)\n",
        "pred_boxes = np.array([\n",
        "    [10, 10, 30, 30],\n",
        "    [15, 15, 40, 40],\n",
        "    [60, 60, 90, 90],\n",
        "])\n",
        "\n",
        "# 각 박스 confidence score\n",
        "pred_scores = np.array([0.9, 0.6, 0.3])\n",
        "\n",
        "# GT 박스들\n",
        "gt_boxes = np.array([\n",
        "    [12, 12, 28, 28],\n",
        "    [50, 50, 80, 80],\n",
        "])\n",
        "\n",
        "ap_05 = compute_map(pred_boxes, pred_scores, gt_boxes, iou_thresh=0.5)\n",
        "print(\"AP@0.5:\", ap_05)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr9LEBMjCRjn",
        "outputId": "4fac6e28-4cc1-49f6-d156-f685a425907b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AP@0.5: 0.49999950000050003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 여러 이미지에서 mAP@0.5 를 구하려면?\n",
        "aps = []\n",
        "for img_idx in range(num_images):\n",
        "    pred_boxes = ...  # img_idx에 대한 예측\n",
        "    pred_scores = ...\n",
        "    gt_boxes = ...\n",
        "\n",
        "    ap_05 = compute_map(pred_boxes, pred_scores, gt_boxes, iou_thresh=0.5)\n",
        "    aps.append(ap_05)\n",
        "\n",
        "mAP_05 = np.mean(aps)\n",
        "print(\"mAP@0.5 over dataset:\", mAP_05)"
      ],
      "metadata": {
        "id": "KgaWgBSNDKJS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 50:95\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def compute_map_50_95(pred_boxes, pred_scores, gt_boxes):\n",
        "    \"\"\"\n",
        "    너가 이미 만든 compute_map()을 이용해서\n",
        "    COCO 스타일 mAP 50:95를 계산하는 예시.\n",
        "\n",
        "    pred_boxes: (N_pred, 4) numpy array, (x1,y1,x2,y2)\n",
        "    pred_scores: (N_pred,) numpy array\n",
        "    gt_boxes: (N_gt, 4) numpy array\n",
        "\n",
        "    return:\n",
        "        mAP_50_95: scalar (float)\n",
        "        aps: dict {iou_threshold: AP 값}\n",
        "    \"\"\"\n",
        "    iou_thresholds = np.arange(0.50, 0.96, 0.05)  # [0.50, 0.55, ..., 0.95]\n",
        "\n",
        "    aps = {}\n",
        "    for thr in iou_thresholds:\n",
        "        ap = compute_map(pred_boxes, pred_scores, gt_boxes, iou_thresh=thr)\n",
        "        aps[thr] = ap\n",
        "\n",
        "    # 10개 IoU threshold에서의 AP 평균\n",
        "    mAP_50_95 = np.mean(list(aps.values()))\n",
        "    return mAP_50_95, aps\n"
      ],
      "metadata": {
        "id": "lvkdy4bTDN8u"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측 박스들 (x1,y1,x2,y2)\n",
        "pred_boxes = np.array([\n",
        "    [10, 10, 30, 30],\n",
        "    [15, 15, 40, 40],\n",
        "    [60, 60, 90, 90],\n",
        "])\n",
        "\n",
        "# 각 박스 confidence score\n",
        "pred_scores = np.array([0.9, 0.6, 0.3])\n",
        "\n",
        "# GT 박스들\n",
        "gt_boxes = np.array([\n",
        "    [12, 12, 28, 28],\n",
        "    [50, 50, 80, 80],\n",
        "])\n",
        "\n",
        "mAP_50_95, aps = compute_map_50_95(pred_boxes, pred_scores, gt_boxes)\n",
        "\n",
        "print(\"mAP 50:95 =\", mAP_50_95)\n",
        "for thr, ap in aps.items():\n",
        "    print(f\"AP@IoU={thr:.2f} = {ap}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Efsr3bLJDuFH",
        "outputId": "804f0e04-8f26-442a-f76f-b9fd90dd8fca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP 50:95 = 0.14999985000015\n",
            "AP@IoU=0.50 = 0.49999950000050003\n",
            "AP@IoU=0.55 = 0.49999950000050003\n",
            "AP@IoU=0.60 = 0.49999950000050003\n",
            "AP@IoU=0.65 = 0.0\n",
            "AP@IoU=0.70 = 0.0\n",
            "AP@IoU=0.75 = 0.0\n",
            "AP@IoU=0.80 = 0.0\n",
            "AP@IoU=0.85 = 0.0\n",
            "AP@IoU=0.90 = 0.0\n",
            "AP@IoU=0.95 = 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Nd5NKmuDuk1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}